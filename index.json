[{"authors":["daniel-alexander"],"categories":null,"content":"Title: Image quality transfer and democratization of MRI\nAbstract: Daniel will talk about some international efforts to democratize MRI expertise and capability. For example the CAMERA network aiming to enhance MR education and research in Africa. Daniel will focus particularly on my work on Image Quality Transfer (Alexander et al Neuroimage 2017; Tanno et al Neuroimage 2021; Lin et al ISMRM 2021), which contributes to this effort. The technique learns models that infer high quality images, e.g. that we would have acquired from a one-off super-powered scanner, from lower quality images, e.g. acquired on a standard hospital scanner or a low-cost low-field scanner situated e.g. in an LMIC clinic. Initially designed for exploiting the rich information from one-off bespoke scanners such as the Connectom scanners (Jones et al Neuroimage 2018), the technique adapts naturally to enhance images from low-power scanners, such as low-field open-magnet or portable MRI scanners, to approximate images from standard high-field scanners. Daniel will talk through the history of development of these ideas, show some of the latest results, speculate about future opportunities, and describe some challenges and observations of implementing these ideas in LMIC scenarios (see link#1; and link#2).\nBiography: Daniel Alexander is Professor in the Computer Science Department at UCL and Director of the UCL Centre for Medical Image Computing. His expertise is in computational modelling, machine learning and pattern recognition, mostly with application to medical data and in particular medical imaging data. He is best known for his work in diffusion MRI microstructure imaging techniques such as NODDI (Zhang et al Neuroimage 2012) for neuroimaging and VERDICT (Panagiotaki et al Cancer Research 2013) for cancer imaging, his work in disease progression modelling using techniques such as the event-based model (Fonteijn et al Neuroimage 2012; Young et al Brain 2014) and the subtype and stage algorithm (Young et al Nature Comms 2018), and more recently his work on image quality transfer (Alexander et al Neuroimage 2017; Tanno et al Neuroimage 2021; Lin et al ISMRM 2021). He has a BA in Mathematics from the University of Oxford (1993), an MSc in Computer Science from UCL (1994), and a PhD in Computer Science from UCL (1998). He worked as a post-doc at the University of Pennsylvania until 2000 when he returned to London to take up an academic position. He became full professor in 2009, Director of CMIC in 2015, and senior fellow of the ISMRM in 2017.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"60695d54c3a09efb0fd23bf7c5103908","permalink":"https://fair-workshop.github.io/author/daniel-alexander/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/daniel-alexander/","section":"authors","summary":"Title: Image quality transfer and democratization of MRI\nAbstract: Daniel will talk about some international efforts to democratize MRI expertise and capability. For example the CAMERA network aiming to enhance MR education and research in Africa.","tags":null,"title":"Daniel Alexander","type":"authors"},{"authors":["diana-mateus"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"286273e44eb803c0de60d3bb89550941","permalink":"https://fair-workshop.github.io/author/diana-mateus/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/diana-mateus/","section":"authors","summary":"","tags":null,"title":"Diana Mateus","type":"authors"},{"authors":["Linda Marrakchi-Kacem"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3834a583caddb2e35d2abe574d66c3fe","permalink":"https://fair-workshop.github.io/author/linda-marrakchi-kacem/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/linda-marrakchi-kacem/","section":"authors","summary":"","tags":null,"title":"Linda Marrakchi-Kacem","type":"authors"},{"authors":["shadi-albarqouni"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"59358bd427e968aae33a13f16b2440a6","permalink":"https://fair-workshop.github.io/author/shadi-albarqouni/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/shadi-albarqouni/","section":"authors","summary":"","tags":null,"title":"Shadi Albarqouni","type":"authors"},{"authors":["zongyuan-ge"],"categories":null,"content":"Title: Close the loop for Medical Ophthalmology AI application\nAbstract: More than 10 million adults suffer from vision impairment or blindness and this number is expected to rise as the population ages in many countries. It is estimated that 80% of vision loss is avoidable through early detection, prevention, and treatment strategies. Despite this, up to 50% of cases of major eye diseases, including diabetic retinopathy (DR) and glaucoma remain undiagnosed, primarily because many of these conditions are silent in their early stages. In this talk, I will conduct a case study on one of the world’s first CFDA \u0026amp; CE \u0026amp; TGA certified multi-label retinal disease diagnosis systems my team have developed together with the medical AI unicorn company Airdoc. Also, I will talk about how this system is being distributed, deployed and make the low-cost, high-quality healthcare service to millions of people.\nBiography: Associate Professor Zongyuan Ge conducts interdisciplinary research at the boundary between medical artificial intelligence, computer-aided diagnosis, biomedical engineering, medical imaging and machine learning and is a multi-award winning medical information science and technology entrepreneur. His research leverages cutting-edge AI technologies using large-scale multi-modality medical data including imaging, medical records, gene data and models the clinicians’ medical knowledge underlying tasks like diagnosis, prognosis and treatment for eye (ophthalmology), skin (dermatology), heart (cardiovascular) and neurodegeneration diseases such as epilepsy and multiple sclerosis. He is also one of Australia’s most in-demand experts in technology, including medical robotics and artificial intelligence, and is a passionate science communicator.\nHe currently holds the position of Associate Professor at the Monash University Vice-Chancellor and Provost Office as well as Faculty of Engineering, Research Affiliate at the Australian Centre for Robotic Vision, NVIDIA AI Fellow, the Chief Scientist at Monash-Airdoc Research Centre and Chief Research Officer at Eyetelligence. He is the founding director of the Monash Medical AI group (https://www.monash.edu/mmai-group) with over fully-funded 20+ PhD students (internal + external), 6 Research Fellows, and 10+ Research Master/FYP students.\nHis research has helped attract more than 25+ million dollars in funding as either primary chief investigator or leading chief investigator from grant bodies, including the National Health and Medical Research Council (NHMRC), Medical Research Future Fund (MRFF), The Australian Research Data Commons (ARDC) and industry funding from NVIDIA, Molemap and Airdoc. Zongyuan’s research papers have been published in top-tier journals and conferences such as The Lancet Digital Health, The British Medical Journal, JAMA, Bioinformatics, Hypertension, IEEE Transactions on Pattern Analysis and Machine Intelligence, IEEE Transactions on Medical Imaging, NeurIPS, CVPR, ICCV, ICLR, KDD, AAAI and MICCAI. His citations h-index is 27, with 4500+ citations only four years post his PhD.\nHe has led and contributed to several international research projects in the areas of dermatology, ophthalmology, radiology and neurology with major industry companies like IBM Watson Health, medical technology unicorn company Airdoc/Eyetelligence and medical/healthcare services providers such as Molemap Clinic, The Alfred Health, Royal Melbourne Hospital, and Princess Alexandra Hospital. His work has been recognised by many international and national awards, including the 200 Most Qualified Young Researchers in Computer and Mathematics by the Scientific Committee of the Heidelberg Laureate Foundation, IBM Scientific Research Accomplishment Award, IBM Manager Choice Award and Monash Exceptional Achievement Award.\nAs a lifelong medical technology entrepreneur, Zongyuan has co-founded and launched the company Eyeyelligence, which targets the massive global optometry and optical dispensing market. Eyetelligence has received funding of over 10 million dollars from various venture capital, family foundation and the Morrison Government. His company has developed the Eyeteligence workstation, which can screen for the four leading causes of blindness in adults: DR, Cataracts, AMD, and Glaucoma and sold to all 48 Australian BUPA Optical stores and all Specsavers 400 Australia and NZ stores. A/Prof is also the Chief Scientist for the Monash-Airdoc Research Centre (https://www.airdoc.com/) to lead the AI technology and product development team. In 2019, he helped build the Monash-Airdoc joint research centre under Monash eResearch centre to develop CFDA CLASS III approved healthcare monitoring products. The products developed by Airdoc and my team have also won honours such as “the highest award of artificial intelligence in China–Wu Wenjun Award for artificial intelligence science and technology” and “the case of Microsoft global AI cooperation in 2018 World Artificial Intelligence …","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"323e970aefa42da7e64a7b36a3b68e10","permalink":"https://fair-workshop.github.io/author/zongyuan-ge/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/zongyuan-ge/","section":"authors","summary":"Title: Close the loop for Medical Ophthalmology AI application\nAbstract: More than 10 million adults suffer from vision impairment or blindness and this number is expected to rise as the population ages in many countries.","tags":null,"title":"Zongyuan Ge","type":"authors"},{"authors":["rakesh-mullick"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c89abcc4cbb34278c3a7c8f04ff00029","permalink":"https://fair-workshop.github.io/author/rakesh-mullick/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/rakesh-mullick/","section":"authors","summary":"","tags":null,"title":"Rakesh Mullick","type":"authors"},{"authors":["Sophia Bano"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"effbea7e05ced2938915ef2255eb57ba","permalink":"https://fair-workshop.github.io/author/sophia-bano/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sophia-bano/","section":"authors","summary":"","tags":null,"title":"Sophia Bano","type":"authors"},{"authors":["Yunusa Mohammed"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"d14f1f65956b93287f5ce7bbff569727","permalink":"https://fair-workshop.github.io/author/yunusa-mohammed/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yunusa-mohammed/","section":"authors","summary":"","tags":null,"title":"Yunusa Mohammed","type":"authors"},{"authors":["aya-salama"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1fa35da7d9df25c4ce3c0765efa77425","permalink":"https://fair-workshop.github.io/author/aya-salama/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/aya-salama/","section":"authors","summary":"","tags":null,"title":"Aya Salama","type":"authors"},{"authors":["bishesh-khanal"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2105ed1a9fdb6fac15d4375101a3a469","permalink":"https://fair-workshop.github.io/author/bishesh-khanal/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/bishesh-khanal/","section":"authors","summary":"","tags":null,"title":"Bishesh Khanal","type":"authors"},{"authors":["nassir-navab"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c441caa9f6eaaaf0e9cc249eac5e451a","permalink":"https://fair-workshop.github.io/author/nassir-navab/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nassir-navab/","section":"authors","summary":"","tags":null,"title":"Nassir Navab","type":"authors"},{"authors":["terry-peters"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"7a7ffede4f1fcceca77a322780f50b7f","permalink":"https://fair-workshop.github.io/author/terry-peters/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/terry-peters/","section":"authors","summary":"","tags":null,"title":"Terry Peters","type":"authors"},{"authors":["yenisel-calana"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f6ccdde747ce1eb32326348732ed91e3","permalink":"https://fair-workshop.github.io/author/yenisel-plasencia-calana/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yenisel-plasencia-calana/","section":"authors","summary":"","tags":null,"title":"Yenisel Plasencia Calaña","type":"authors"},{"authors":["aisha-walcott-bryant"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8c03b31406da5a2335218917eecf0155","permalink":"https://fair-workshop.github.io/author/aisha-walcott-bryant/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/aisha-walcott-bryant/","section":"authors","summary":"","tags":null,"title":"Aisha Walcott-Bryant","type":"authors"},{"authors":["Farah Shamout"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8074842bc47c398b011c0c5783d1d28c","permalink":"https://fair-workshop.github.io/author/farah-shamout/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/farah-shamout/","section":"authors","summary":"","tags":null,"title":"Farah Shamout","type":"authors"},{"authors":["Islem Rekik"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bed5929deeb4957478c0278f812b8c49","permalink":"https://fair-workshop.github.io/author/islem-rekik/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/islem-rekik/","section":"authors","summary":"","tags":null,"title":"Islem Rekik","type":"authors"},{"authors":["Nicola Rieke"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"0beeece57f244832fea0cd348e7421be","permalink":"https://fair-workshop.github.io/author/nicola-rieke/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nicola-rieke/","section":"authors","summary":"","tags":null,"title":"Nicola Rieke","type":"authors"},{"authors":["Debdoot Sheet"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1f551f7eaef5a40ecf08d487bbc26cf9","permalink":"https://fair-workshop.github.io/author/debdoot-sheet/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/debdoot-sheet/","section":"authors","summary":"","tags":null,"title":"Debdoot Sheet","type":"authors"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\n Create slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://fair-workshop.github.io/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/example/","section":"event","summary":"An example event.","tags":[],"title":"Example Event","type":"event"},{"authors":["admin"],"categories":[[]],"content":"Keynote 1: dsdsds\n","date":1654646400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654646400,"objectID":"9e8941ebeaf2378fa451a5103fc16c7a","permalink":"https://fair-workshop.github.io/old_speakers/speaker1/","publishdate":"2022-06-08T00:00:00Z","relpermalink":"/old_speakers/speaker1/","section":"old_speakers","summary":"TBC","tags":null,"title":"Keynote: TBC","type":"old_speakers"},{"authors":null,"categories":null,"content":"Congratulations to Jian Yang and Monica Hall for winning the Best Paper Award at the 2020 Conference on Wowchemy for their paper “Learning Wowchemy”.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Integer tempus augue non tempor egestas. Proin nisl nunc, dignissim in accumsan dapibus, auctor ullamcorper neque. Quisque at elit felis. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget elementum odio. Cras interdum eget risus sit amet aliquet. In volutpat, nisl ut fringilla dignissim, arcu nisl suscipit ante, at accumsan sapien nisl eu eros.\nSed eu dui nec ligula bibendum dapibus. Nullam imperdiet auctor tortor, vel cursus mauris malesuada non. Quisque ultrices euismod dapibus. Aenean sed gravida risus. Sed nisi tortor, vulputate nec quam non, placerat porta nisl. Nunc varius lobortis urna, condimentum facilisis ipsum molestie eu. Ut molestie eleifend ligula sed dignissim. Duis ut tellus turpis. Praesent tincidunt, nunc sed congue malesuada, mauris enim maximus massa, eget interdum turpis urna et ante. Morbi sem nisl, cursus quis mollis et, interdum luctus augue. Aliquam laoreet, leo et accumsan tincidunt, libero neque aliquet lectus, a ultricies lorem mi a orci.\nMauris dapibus sem vel magna convallis laoreet. Donec in venenatis urna, vitae sodales odio. Praesent tortor diam, varius non luctus nec, bibendum vel est. Quisque id sem enim. Maecenas at est leo. Vestibulum tristique pellentesque ex, blandit placerat nunc eleifend sit amet. Fusce eget lectus bibendum, accumsan mi quis, luctus sem. Etiam vitae nulla scelerisque, eleifend odio in, euismod quam. Etiam porta ullamcorper massa, vitae gravida turpis euismod quis. Mauris sodales sem ac ultrices viverra. In placerat ultrices sapien. Suspendisse eu arcu hendrerit, luctus tortor cursus, maximus dolor. Proin et velit et quam gravida dapibus. Donec blandit justo ut consequat tristique.\n","date":1606867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606867200,"objectID":"bb3d001b4a7dcae1a43ae887afbceb6e","permalink":"https://fair-workshop.github.io/post/speaker2/","publishdate":"2020-12-02T00:00:00Z","relpermalink":"/post/speaker2/","section":"post","summary":"Congratulations to Jian Yang and Monica Hall for winning the Best Paper Award at the 2020 Conference on Wowchemy for their paper “Learning Wowchemy”.\n","tags":null,"title":"Jian Yang and Monica Hall Win the Best Paper Award at Wowchemy 2020","type":"post"},{"authors":null,"categories":null,"content":"Congratulations to Richard Hendricks for winning first place in the Wowchemy Prize.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Integer tempus augue non tempor egestas. Proin nisl nunc, dignissim in accumsan dapibus, auctor ullamcorper neque. Quisque at elit felis. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget elementum odio. Cras interdum eget risus sit amet aliquet. In volutpat, nisl ut fringilla dignissim, arcu nisl suscipit ante, at accumsan sapien nisl eu eros.\nSed eu dui nec ligula bibendum dapibus. Nullam imperdiet auctor tortor, vel cursus mauris malesuada non. Quisque ultrices euismod dapibus. Aenean sed gravida risus. Sed nisi tortor, vulputate nec quam non, placerat porta nisl. Nunc varius lobortis urna, condimentum facilisis ipsum molestie eu. Ut molestie eleifend ligula sed dignissim. Duis ut tellus turpis. Praesent tincidunt, nunc sed congue malesuada, mauris enim maximus massa, eget interdum turpis urna et ante. Morbi sem nisl, cursus quis mollis et, interdum luctus augue. Aliquam laoreet, leo et accumsan tincidunt, libero neque aliquet lectus, a ultricies lorem mi a orci.\nMauris dapibus sem vel magna convallis laoreet. Donec in venenatis urna, vitae sodales odio. Praesent tortor diam, varius non luctus nec, bibendum vel est. Quisque id sem enim. Maecenas at est leo. Vestibulum tristique pellentesque ex, blandit placerat nunc eleifend sit amet. Fusce eget lectus bibendum, accumsan mi quis, luctus sem. Etiam vitae nulla scelerisque, eleifend odio in, euismod quam. Etiam porta ullamcorper massa, vitae gravida turpis euismod quis. Mauris sodales sem ac ultrices viverra. In placerat ultrices sapien. Suspendisse eu arcu hendrerit, luctus tortor cursus, maximus dolor. Proin et velit et quam gravida dapibus. Donec blandit justo ut consequat tristique.\n","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"641e86601cda641fe29b6c42cf40f58d","permalink":"https://fair-workshop.github.io/post/speaker1/","publishdate":"2020-12-01T00:00:00Z","relpermalink":"/post/speaker1/","section":"post","summary":"Congratulations to Richard Hendricks for winning first place in the Wowchemy Prize.\n","tags":null,"title":"Richard Hendricks Wins First Place in the Wowchemy Prize","type":"post"},{"authors":["admin"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://fair-workshop.github.io/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":["admin","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://fair-workshop.github.io/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["admin","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://fair-workshop.github.io/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://fair-workshop.github.io/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ae2b9e20728a7935c40f33b3013854dd","permalink":"https://fair-workshop.github.io/keynotes/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/keynotes/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://fair-workshop.github.io/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1d0bdff647cd5341f2c35bd74792e0ea","permalink":"https://fair-workshop.github.io/fair2021/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/fair2021/","section":"","summary":"","tags":null,"title":"FAIR 2021","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"https://fair-workshop.github.io/tour/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/tour/","section":"","summary":"","tags":null,"title":"Tour","type":"widget_page"}]